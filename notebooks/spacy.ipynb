{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2531bc29-725e-42bb-aa89-a818f8af2ba9",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "**Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11fb59-6897-4520-ba0c-0e3b7f7fcdfc",
   "metadata": {},
   "source": [
    "# Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdad7de4-c415-41f4-92dd-52e48a5d44f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98904d-f5ff-4ddf-b1e1-5bfba1658894",
   "metadata": {},
   "source": [
    "# Loading Spacy language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0a0a17-d34a-479a-b2db-54ca89892b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcf72e6-3c86-4647-8357-c46a8c9be744",
   "metadata": {},
   "source": [
    "# Adding a demo text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbf4af1c-cbb9-4298-87b2-5ec0fa035896",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'In 2023, At the intersection of linguistics, computer science, and artificial intelligence lies the vast subfield of Natural Language Processing, otherwise known simply as NLP. The focus of NLP is human-machine interaction.The field of NLP uses multiple algorithms to solve various tasks made up of many different data types.Given the vast differences between tasks, algorithms, and data types in this field, the way that we work with and process the data to complete these tasks varies greatly between them')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd13eca1-5529-4160-a9fa-8d49c8ffb99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33795d83-ae60-4fb7-a0e1-7f08a743550d",
   "metadata": {},
   "source": [
    "# Tokenize and print the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea485bfa-622e-49d9-b6c4-c0bb287246f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text            pos             dep        tag        alpha      stop_word \n",
      "In              ADP             prep       IN         1          1         \n",
      "2023            NUM             pobj       CD         0          0         \n",
      ",               PUNCT           punct      ,          0          0         \n",
      "At              ADP             prep       IN         1          1         \n",
      "the             DET             det        DT         1          1         \n",
      "intersection    NOUN            pobj       NN         1          0         \n",
      "of              ADP             prep       IN         1          1         \n",
      "linguistics     NOUN            pobj       NNS        1          0         \n",
      ",               PUNCT           punct      ,          0          0         \n",
      "computer        NOUN            compound   NN         1          0         \n",
      "science         NOUN            conj       NN         1          0         \n",
      ",               PUNCT           punct      ,          0          0         \n",
      "and             CCONJ           cc         CC         1          1         \n",
      "artificial      ADJ             amod       JJ         1          0         \n",
      "intelligence    NOUN            conj       NN         1          0         \n",
      "lies            VERB            ROOT       VBZ        1          0         \n"
     ]
    }
   ],
   "source": [
    "print(\"{:<15} {:<15} {:<10} {:<10} {:<10} {:<10}\".format('text','pos','dep','tag','alpha','stop_word'))\n",
    "for token in doc[:16]:\n",
    "    print(\"{:<15} {:<15} {:<10} {:<10} {:<10} {:<10}\".format(token.text,#give token text\n",
    "          token.pos_,#give token part of speech\n",
    "          token.dep_,# give syntactic dependency\n",
    "          token.tag_,\n",
    "          token.is_alpha,\n",
    "          token.is_stop)\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7bcf5-d44b-4b7c-8d6a-d7db8765991d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
